{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "136da7ea",
   "metadata": {},
   "source": [
    "# Step 1: Scope the Project and Gather Data\n",
    "Since the scope of the project will be highly dependent on the data, these two things happen simultaneously. In this step, youâ€™ll:\n",
    "\n",
    "Identify and gather the data you'll be using for your project (at least two sources and more than 1 million rows). See Project Resources for ideas of what data you can use.\n",
    "Explain what end use cases you'd like to prepare the data for (e.g., analytics table, app back-end, source-of-truth database, etc.)\n",
    "\n",
    "- Step 2: Explore and Assess the Data\n",
    "Explore the data to identify data quality issues, like missing values, duplicate data, etc.\n",
    "Document steps necessary to clean the data\n",
    "- Step 3: Define the Data Model\n",
    "Map out the conceptual data model and explain why you chose that model\n",
    "List the steps necessary to pipeline the data into the chosen data model\n",
    "- Step 4: Run ETL to Model the Data\n",
    "Create the data pipelines and the data model\n",
    "Include a data dictionary\n",
    "Run data quality checks to ensure the pipeline ran as expected\n",
    "Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    "Unit tests for the scripts to ensure they are doing the right thing\n",
    "Source/count checks to ensure completeness\n",
    "- Step 5: Complete Project Write Up\n",
    "What's the goal? What queries will you want to run? How would Spark or Airflow be incorporated? Why did you choose the model you chose?\n",
    "Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "Document the steps of the process.\n",
    "Propose how often the data should be updated and why.\n",
    "Post your write-up and final data model in a GitHub repo.\n",
    "Include a description of how you would approach the problem differently under the following scenarios:\n",
    "If the data was increased by 100x.\n",
    "If the pipelines were run on a daily basis by 7am.\n",
    "If the database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41262bc",
   "metadata": {},
   "source": [
    "# 1 Scope\n",
    "\n",
    "Scrape a custom API of a mobile app to gather the underlying data. After some data modeling we will be able to use this to perform some analytics and create some visualizations. The topic of this project is gin, thus there will be some quantifyable elements in our data, some factual elements, but also a lot of personal opinions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9242fd",
   "metadata": {},
   "source": [
    "# Reverse-engineering a private API\n",
    "\n",
    "The only place I was able to find the information I was looking for (some data on different gin brands) was stuck behind an iOS/Android app. The following is a high level description of the setup process on how to access a private API of a mobile app, you can find further resources in the provided links.\n",
    "- The simplest way to approach the problem is to use an Android emulator, in this case I used Android Studio. Due to Android's strict Certificate Authority management it is a bit finicky to setup mitmproxy with a system certificate on an Android emulator. An alternative is using a rooted physical device, in which case you will have a much easier time with CA management.\n",
    "- Download an APK version of your target app, and install it on the emulated device. \n",
    "- Install ADB, and make sure to add the platform-tools folder to your PATH variable. --> Guide Check if your emulator is connected to ADB with ADB devices.\n",
    "- Install HTTP Toolkit. Select Android device via ADB as your traffic source and follow setup steps in the emulator.\n",
    "- Done! You should be able to see HTTP requests coming in from the emulator.\n",
    "- All there is left to do is find the GET request that you are after, find the URL structure and the API key which we will use to authenticate our requests.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211cd23f",
   "metadata": {},
   "source": [
    "One of the first requests the app sends returns the full list of gins/tonics on the site, with a reduced number of fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6272d169",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "import numpy as np\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc5a02e",
   "metadata": {},
   "source": [
    "# Get requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b74bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseURL = 'https://ginventory.reed.be/api/v2/products/{}?api_key={}&lang=en'\n",
    "api_key = '175405344b34bde70ef2970b44e8f07d'\n",
    "headers = {\n",
    "    'User-Agent': 'Test, Peter Oravecz',\n",
    "    'From': 'peteroravecz9@gmail.com'\n",
    "}\n",
    "\n",
    "response_collection = {'data' : []}\n",
    "for i in range(1,100):\n",
    "    url = baseURL.format(i, api_key)\n",
    "    response = requests.get(url, headers = headers)\n",
    "    print(i)\n",
    "    response_collection['data'].append(response.json())\n",
    "    time.sleep(0.1)\n",
    "    \n",
    "with open('data_100.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(response_collection, f, ensure_ascii=False, indent=4)\n",
    "print(\"Responses collected!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e38123b",
   "metadata": {},
   "source": [
    "# Read in requests from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2971fec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(\"data_100.json\", 'r', encoding='utf-8') as file:\n",
    "    file_json = json.load(file)\n",
    "df = pd.json_normalize(file_json, record_path=['data'])\n",
    "df = df.drop(['perfect_tonics.data','perfect_garnishes.data', 'purchase_links.data', 'perfect_gins.data'], axis=1)\n",
    "df = df[df.type == 'gin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a192e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ba0025",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
